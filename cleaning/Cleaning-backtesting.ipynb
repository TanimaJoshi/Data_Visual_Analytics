{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_table(db_path, table_name, id_columns=None, replace=True):\n",
    "    \"\"\"Clean table by removing duplicates and basic data cleaning\"\"\"\n",
    "    # Connect to database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    print(f\"Connected to {db_path}\")\n",
    "    \n",
    "    # Load table to DataFrame\n",
    "    df = pd.read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
    "    print(f\"Original rows: {len(df)}\")\n",
    "    \n",
    "    # Use all columns for deduplication if none specified\n",
    "    if id_columns is None:\n",
    "        id_columns = df.columns.tolist()\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df_clean = df.drop_duplicates(subset=id_columns)\n",
    "    print(f\"Removed {len(df) - len(df_clean)} duplicates\")\n",
    "    \n",
    "    # Basic cleaning: handle nulls in string columns and trim whitespace\n",
    "    for col in df_clean.select_dtypes(include=['object']):\n",
    "        df_clean[col] = df_clean[col].fillna('').astype(str).str.strip()\n",
    "    \n",
    "    # Save cleaned data\n",
    "    if replace:\n",
    "        df_clean.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "        print(f\"Replaced {table_name} with {len(df_clean)} clean rows\")\n",
    "    else:\n",
    "        new_table = f\"{table_name}_clean\"\n",
    "        df_clean.to_sql(new_table, conn, if_exists='replace', index=False)\n",
    "        print(f\"Created {new_table} with {len(df_clean)} clean rows\")\n",
    "    \n",
    "    conn.close()\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to occupation_salaries (2).db\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "clean_df = clean_table(\"occupation_salaries (2).db\", \"Final_Combined_Data\", replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with shape: (4162883, 20)\n"
     ]
    }
   ],
   "source": [
    "# # Connect to your database - update the path to your actual database\n",
    "# conn = sqlite3.connect(\"occupation_salaries (2).db\")\n",
    "\n",
    "# # Query to get your data\n",
    "# query = '''SELECT YEAR, OCC_TITLE, AREA_TITLE, PRIM_STATE\n",
    "#            FROM Final_Combined_Data_clean'''\n",
    "\n",
    "# df = pd.read_sql_query(query, conn)\n",
    "# conn.close()\n",
    "\n",
    "# Connect to your database\n",
    "conn = sqlite3.connect(\"occupation_salaries (2).db\")\n",
    "\n",
    "# Expanded query to get more columns\n",
    "query = '''SELECT YEAR, OCC_TITLE, AREA_TITLE, PRIM_STATE, \n",
    "           tot_emp, jobs_1000, loc_quotient, h_mean, a_mean, h_median, a_median,\n",
    "           emp_prse, mean_prse, naics, naics_title, i_group, own_code, occ_code,\n",
    "           o_group, area_type\n",
    "           FROM Final_Combined_Data_clean'''\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Print shape to confirm data was loaded\n",
    "print(f\"Loaded data with shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (4162883, 20)\n",
      "\n",
      "Sample data:\n",
      "   YEAR                        OCC_TITLE AREA_TITLE PRIM_STATE  TOT_EMP  \\\n",
      "0  2014                  All Occupations    Alabama             1857530   \n",
      "1  2014           Management Occupations    Alabama               67500   \n",
      "2  2014                 Chief Executives    Alabama                1080   \n",
      "3  2014  General and Operations Managers    Alabama               26480   \n",
      "4  2014                      Legislators    Alabama                1470   \n",
      "\n",
      "  JOBS_1000 LOC_QUOTIENT H_MEAN    A_MEAN H_MEDIAN  A_MEDIAN EMP_PRSE  \\\n",
      "0    1000.0          1.0  19.66   40890.0    14.83   30850.0      0.4   \n",
      "1    36.338         0.73  51.48  107080.0    44.98   93550.0      1.1   \n",
      "2      0.58         0.32  97.67  203150.0        #         #      4.8   \n",
      "3    14.258         0.94   58.0  120640.0     49.0  101930.0      1.5   \n",
      "4      0.79         1.94      *   21920.0        *   18450.0      8.7   \n",
      "\n",
      "  MEAN_PRSE   NAICS     NAICS_TITLE I_GROUP OWN_CODE OCC_CODE O_GROUP  \\\n",
      "0       0.5  000000  Cross-industry             1235  00-0000           \n",
      "1       0.6  000000  Cross-industry             1235  11-0000           \n",
      "2       2.5  000000  Cross-industry             1235  11-1011           \n",
      "3       0.9  000000  Cross-industry             1235  11-1021           \n",
      "4       3.5  000000  Cross-industry             1235  11-1031           \n",
      "\n",
      "  AREA_TYPE  \n",
      "0         2  \n",
      "1         2  \n",
      "2         2  \n",
      "3         2  \n",
      "4         2  \n",
      "\n",
      "Null values: YEAR            0\n",
      "OCC_TITLE       0\n",
      "AREA_TITLE      0\n",
      "PRIM_STATE      0\n",
      "TOT_EMP         0\n",
      "JOBS_1000       0\n",
      "LOC_QUOTIENT    0\n",
      "H_MEAN          0\n",
      "A_MEAN          0\n",
      "H_MEDIAN        0\n",
      "A_MEDIAN        0\n",
      "EMP_PRSE        0\n",
      "MEAN_PRSE       0\n",
      "NAICS           0\n",
      "NAICS_TITLE     0\n",
      "I_GROUP         0\n",
      "OWN_CODE        0\n",
      "OCC_CODE        0\n",
      "O_GROUP         0\n",
      "AREA_TYPE       0\n",
      "dtype: int64\n",
      "\n",
      "Unique occupation titles: 1309\n",
      "\n",
      "Year range: 2014 to 2023\n",
      "DataFrame columns:\n",
      "['YEAR', 'OCC_TITLE', 'AREA_TITLE', 'PRIM_STATE', 'TOT_EMP', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'H_MEDIAN', 'A_MEDIAN', 'EMP_PRSE', 'MEAN_PRSE', 'NAICS', 'NAICS_TITLE', 'I_GROUP', 'OWN_CODE', 'OCC_CODE', 'O_GROUP', 'AREA_TYPE']\n"
     ]
    }
   ],
   "source": [
    "# Basic data exploration\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(\"\\nSample data:\")\n",
    "print(df.head())\n",
    "print(\"\\nNull values:\", df.isnull().sum())\n",
    "print(\"\\nUnique occupation titles:\", df.OCC_TITLE.nunique())\n",
    "print(\"\\nYear range:\", df.YEAR.min(), \"to\", df.YEAR.max())\n",
    "# Print all columns in the DataFrame\n",
    "print(\"DataFrame columns:\")\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "le_occupation = LabelEncoder()\n",
    "le_area = LabelEncoder()\n",
    "le_state = LabelEncoder()\n",
    "\n",
    "df['OCC_TITLE_ENCODED'] = le_occupation.fit_transform(df['OCC_TITLE'])\n",
    "df['AREA_TITLE_ENCODED'] = le_area.fit_transform(df['AREA_TITLE'])\n",
    "df['PRIM_STATE_ENCODED'] = le_state.fit_transform(df['PRIM_STATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix with all available features\n",
    "features = [col for col in df.columns if col not in ['YEAR', 'TOT_EMP', 'JOBS_1000', \n",
    "            'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'H_MEDIAN', 'A_MEDIAN', 'EMP_PRSE', \n",
    "            'MEAN_PRSE', 'AREA_TYPE', 'OCC_TITLE_ENCODED', 'AREA_TITLE_ENCODED', 'PRIM_STATE_ENCODED']]\n",
    "X = df[features].copy()\n",
    "\n",
    "# Handle missing values\n",
    "for col in X.columns:\n",
    "    if X[col].dtype.kind in 'fiuO':  # numeric or object columns\n",
    "        X[col] = X[col].fillna(0 if X[col].dtype.kind in 'fiu' else 'unknown')\n",
    "\n",
    "y = df['OCC_TITLE_ENCODED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 9 object columns to numeric\n",
      "\n",
      "Data types after numeric conversion:\n",
      "OCC_TITLE      float64\n",
      "AREA_TITLE     float64\n",
      "PRIM_STATE     float64\n",
      "NAICS          float64\n",
      "NAICS_TITLE    float64\n",
      "I_GROUP        float64\n",
      "OWN_CODE       float64\n",
      "OCC_CODE       float64\n",
      "O_GROUP        float64\n",
      "dtype: object\n",
      "\n",
      "All columns successfully converted to numeric types\n"
     ]
    }
   ],
   "source": [
    "# Convert object columns to numeric if they contain numbers\n",
    "object_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Converting {len(object_cols)} object columns to numeric\")\n",
    "\n",
    "for col in object_cols:\n",
    "    # Try to convert to numeric, errors='coerce' will set non-convertible values to NaN\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "    \n",
    "    # Fill NaN values with 0\n",
    "    X[col] = X[col].fillna(0)\n",
    "    \n",
    "# Check the data types after conversion\n",
    "print(\"\\nData types after numeric conversion:\")\n",
    "print(X.dtypes)\n",
    "\n",
    "# Verify we have no object columns left\n",
    "remaining_objects = X.select_dtypes(include=['object']).columns.tolist()\n",
    "if remaining_objects:\n",
    "    print(f\"\\nStill have {len(remaining_objects)} object columns: {remaining_objects}\")\n",
    "else:\n",
    "    print(\"\\nAll columns successfully converted to numeric types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data by YEAR - train: all be last year, test: last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on years: ['2014' '2015' '2016' '2017' '2018' '2019' '2020' '2021' '2022']\n",
      "Testing on year: 2023\n",
      "Total training samples: 3749556\n"
     ]
    }
   ],
   "source": [
    "# Split data by time\n",
    "years = df.YEAR.unique()\n",
    "years.sort()\n",
    "train_years = years[:-1]  # Use all but the last year for training\n",
    "test_year = years[-1]     # Use the last year for testing\n",
    "\n",
    "X_train = X[df.YEAR.isin(train_years)]\n",
    "y_train = y[df.YEAR.isin(train_years)]\n",
    "X_test = X[df.YEAR == test_year]\n",
    "y_test = y[df.YEAR == test_year]\n",
    "\n",
    "print(f\"\\nTraining on years: {train_years}\")\n",
    "print(f\"Testing on year: {test_year}\")\n",
    "print(f\"Total training samples: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 187477 samples (5.0%) for feature selection\n"
     ]
    }
   ],
   "source": [
    "# Sample the training data to speed up feature selection\n",
    "sample_size = 0.05  # Use 5% of the data\n",
    "sample_indices = np.random.choice(len(X_train), size=int(len(X_train) * sample_size), replace=False)\n",
    "X_train_sample = X_train.iloc[sample_indices]\n",
    "y_train_sample = y_train.iloc[sample_indices]\n",
    "\n",
    "print(f\"Using {len(X_train_sample)} samples ({sample_size*100:.1f}%) for feature selection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected 2 features out of 9:\n",
      "['NAICS', 'OWN_CODE']\n",
      "\n",
      "Original feature count: 9\n",
      "Reduced feature count: 2\n",
      "\n",
      "Top 10 features by importance:\n",
      "1. NAICS (0.8732)\n",
      "2. OWN_CODE (0.1268)\n",
      "3. O_GROUP (0.0000)\n",
      "4. OCC_CODE (0.0000)\n",
      "5. I_GROUP (0.0000)\n",
      "6. NAICS_TITLE (0.0000)\n",
      "7. PRIM_STATE (0.0000)\n",
      "8. AREA_TITLE (0.0000)\n",
      "9. OCC_TITLE (0.0000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Use a model for feature selection\n",
    "selector = SelectFromModel(RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42))\n",
    "selector.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Get selected features\n",
    "feature_mask = selector.get_support()\n",
    "selected_features = X.columns[feature_mask]\n",
    "print(f\"\\nSelected {len(selected_features)} features out of {len(X.columns)}:\")\n",
    "print(selected_features.tolist())\n",
    "\n",
    "# Create datasets with only selected features\n",
    "X_train_selected = X_train.loc[:, feature_mask]\n",
    "X_test_selected = X_test.loc[:, feature_mask]\n",
    "\n",
    "print(f\"\\nOriginal feature count: {X_train.shape[1]}\")\n",
    "print(f\"Reduced feature count: {X_train_selected.shape[1]}\")\n",
    "\n",
    "# Print top 10 feature importance scores\n",
    "if hasattr(selector.estimator_, 'feature_importances_'):\n",
    "    importances = selector.estimator_.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    print(\"\\nTop 10 features by importance:\")\n",
    "    for i, idx in enumerate(indices[:10]):\n",
    "        print(f\"{i+1}. {X.columns[idx]} ({importances[idx]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all features to train/test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/OMSA Course Work/CSE 4242 - DVA/Final Project/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prophet import Prophet\n",
    "\n",
    "# Set quieter logging for Prophet and smaller-sized models\n",
    "import logging\n",
    "logging.getLogger('prophet').setLevel(logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on years: ['2014' '2015' '2016' '2017' '2018' '2019' '2020' '2021' '2022'], Testing on year: 2023\n",
      "Training samples: 3749556, Testing samples: 413327\n",
      "Using 187477 samples (5.0%) for model training\n"
     ]
    }
   ],
   "source": [
    "# Directly select these specific columns as features - not exclude them\n",
    "feature_columns = ['YEAR', 'TOT_EMP', 'JOBS_1000', \n",
    "                  'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'H_MEDIAN', 'A_MEDIAN', 'EMP_PRSE', \n",
    "                  'MEAN_PRSE', 'AREA_TYPE', 'OCC_TITLE_ENCODED', 'AREA_TITLE_ENCODED', 'PRIM_STATE_ENCODED']\n",
    "\n",
    "# Define X and y - explicitly use the columns you specified\n",
    "X = df[feature_columns].copy()\n",
    "y = df['OCC_TITLE_ENCODED']\n",
    "\n",
    "# Convert object columns to numeric\n",
    "object_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in object_cols:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Split data by time\n",
    "years = df.YEAR.unique()\n",
    "years.sort()\n",
    "train_years = years[:-1]  # Use all but the last year for training\n",
    "test_year = years[-1]     # Use the last year for testing\n",
    "\n",
    "# Split the data\n",
    "X_train = X[df.YEAR.isin(train_years)]\n",
    "y_train = y[df.YEAR.isin(train_years)]\n",
    "X_test = X[df.YEAR == test_year]\n",
    "y_test = y[df.YEAR == test_year]\n",
    "\n",
    "print(f\"Training on years: {train_years}, Testing on year: {test_year}\")\n",
    "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n",
    "\n",
    "# Sample training data for faster processing\n",
    "sample_size = 0.05  # Use 5% of the data\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(len(X_train), size=int(len(X_train) * sample_size), replace=False)\n",
    "X_train_sample = X_train.iloc[sample_indices]\n",
    "y_train_sample = y_train.iloc[sample_indices]\n",
    "\n",
    "print(f\"Using {len(X_train_sample)} samples ({sample_size*100:.1f}%) for model training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f\"Random Forest Accuracy on test year {test_year}: {rf_accuracy:.4f}\")\n",
    "\n",
    "# Print feature importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train_sample.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importances)\n",
    "\n",
    "# Save the model for later use\n",
    "import joblib\n",
    "joblib.dump(rf_model, 'random_forest_model.joblib')\n",
    "print(\"Model saved as 'random_forest_model.joblib'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
